{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of liblinear is 0.782312925170068\n",
      "Accuracy2 of saga solver is 0.780952380952381\n",
      "Accuracy3 of sag solver is 0.780952380952381\n",
      "ingredients: Index(['black_pepper', 'nira', 'pork', 'sesame_oil', 'wheat'], dtype='object')\n",
      "cuisine: chinese\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.70      0.71      0.70       141\n",
      "      indian       0.90      0.90      0.90       181\n",
      "    japanese       0.68      0.58      0.63       101\n",
      "      korean       0.78      0.86      0.82       229\n",
      "        thai       0.79      0.69      0.74        83\n",
      "\n",
      "    accuracy                           0.78       735\n",
      "   macro avg       0.77      0.75      0.76       735\n",
      "weighted avg       0.78      0.78      0.78       735\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.69      0.71      0.70       141\n",
      "      indian       0.90      0.90      0.90       181\n",
      "    japanese       0.68      0.58      0.63       101\n",
      "      korean       0.78      0.85      0.81       229\n",
      "        thai       0.79      0.69      0.74        83\n",
      "\n",
      "    accuracy                           0.78       735\n",
      "   macro avg       0.77      0.75      0.76       735\n",
      "weighted avg       0.78      0.78      0.78       735\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.69      0.71      0.70       141\n",
      "      indian       0.90      0.90      0.90       181\n",
      "    japanese       0.68      0.58      0.63       101\n",
      "      korean       0.78      0.85      0.81       229\n",
      "        thai       0.79      0.69      0.74        83\n",
      "\n",
      "    accuracy                           0.78       735\n",
      "   macro avg       0.77      0.75      0.76       735\n",
      "weighted avg       0.78      0.78      0.78       735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "cuisines_df  = pd.read_csv('C:/Users/pc/Downloads/cuisines (2).csv')\n",
    "cuisines_label_df = cuisines_df['cuisine']\n",
    "cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)\n",
    "lr = LogisticRegression(multi_class='ovr',solver='liblinear')\n",
    "saga = LogisticRegression(multi_class='ovr',solver='saga')\n",
    "sag = LogisticRegression(multi_class='ovr',solver='sag')\n",
    "model = lr.fit(X_train, np.ravel(y_train))\n",
    "model2=saga.fit(X_train, np.ravel(y_train))\n",
    "model3=sag.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "accuaracy2=model2.score(X_test, y_test)\n",
    "accuaracy3=model3.score(X_test, y_test)\n",
    "print (\"Accuracy of liblinear is {}\".format(accuracy))\n",
    "print (\"Accuracy2 of saga solver is {}\".format(accuaracy2))\n",
    "print (\"Accuracy3 of sag solver is {}\".format(accuaracy3))\n",
    "\n",
    "print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')\n",
    "print(f'cuisine: {y_test.iloc[50]}')\n",
    "test= X_test.iloc[50].values.reshape(-1, 1).T\n",
    "proba = model.predict_proba(test)\n",
    "proba2=model2.predict_proba(test)\n",
    "proba3=model3.predict_proba(test)\n",
    "classes = model.classes_\n",
    "classes2=model2.classes_\n",
    "classes3=model3.classes_\n",
    "resultdf = pd.DataFrame(data=proba, columns=classes)\n",
    "resultdf2 = pd.DataFrame(data=proba2, columns=classes2)\n",
    "resultdf3= pd.DataFrame(data=proba3, columns=classes3)\n",
    "\n",
    "topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])\n",
    "topPrediction2 = resultdf2.T.sort_values(by=[0], ascending = [False])\n",
    "topPrediction3 = resultdf3.T.sort_values(by=[0], ascending = [False])\n",
    "topPrediction.head()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred2=model2.predict(X_test)\n",
    "y_pred3=model3.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('2',classification_report(y_test,y_pred2))\n",
    "print('3',classification_report(y_test,y_pred3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above observations, it is evident that when using different solver parameters, the results obtained from liblinear, saga, and sag are nearly identical. Specifically, the results between saga and sag consistently show minimal differences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
